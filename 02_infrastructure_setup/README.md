# ğŸ› ï¸ Fondasi Infrastruktur: Orkestrasi Ekosistem Big Data Analisis Kemacetan Medan dengan Docker

Selamat datang di **pusat kendali infrastruktur** proyek kami! Di sini, kami merinci konfigurasi untuk membangun lingkungan Big Data yang *reproducible*, *scalable*, dan *isolated* menggunakan **Docker dan Docker Compose**.

## ğŸ¯ Filosofi Desain Infrastruktur:

1.  ğŸŒ **Reproducibility & Portability**: Lingkungan mudah direplikasi di berbagai platform.
2.  ğŸ›¡ï¸ **Isolation**: Setiap layanan (Hadoop, Spark, Hive) berjalan terisolasi dalam container.
3.  ğŸ§± **Modularity**: Komponen individual mudah ditambah, dihapus, atau diperbarui.
4.  ğŸš€ **Ease of Deployment**: Seluruh stack teknologi dijalankan dengan satu perintah Docker Compose.
5.  ğŸŒ **Simulation of Production**: Arsitektur lokal mensimulasikan cluster terdistribusi.

## ğŸ“ Komponen Kunci Infrastruktur:

* **`docker_configs/`**: ğŸ“œ Berisi `Dockerfile` kustom dan file konfigurasi spesifik untuk setiap layanan (Hadoop, Spark, Hive, Superset, Airflow), memastikan jaringan, volume, dan resource optimal.
* **`cluster_init_scripts/`**: ğŸª„ Skrip otomatisasi (seperti `init_hdfs_dirs.sh`) untuk setup awal HDFS (Bronze, Silver, Gold, models) dan perizinan, dirancang agar *idempotent*.
* **`docker-compose.yml`**: ğŸ¼ Orkestrator utama yang mendefinisikan seluruh layanan, jaringan, volume, dan dependensi, memungkinkan seluruh ekosistem dihidupkan atau dimatikan secara terkoordinasi.

**Kredibilitas dan Keandalan**: Pendekatan berbasis Docker ini menerapkan praktik DevOps modern. Dokumentasi detail dan konfigurasi yang cermat memastikan infrastruktur ini berfungsi, mudah dipahami, dimodifikasi, dan dipelihara, mendukung alur kerja analisis data *end-to-end*.
